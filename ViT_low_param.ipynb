{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vit import Vit\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=manual_transforms\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=manual_transforms\n",
    ")\n",
    "batch_size = 16\n",
    "subset_indices = torch.randperm(len(training_data))[:10000]\n",
    "train_subset = Subset(training_data,subset_indices)\n",
    "\n",
    "test_subset_indices = torch.randperm(len(test_data))[:10000]\n",
    "test_subset = Subset(test_data,test_subset_indices)\n",
    "train_dataloader = DataLoader(train_subset,batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_subset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Vit(img_size=224,\n",
    "            in_channels=1,\n",
    "            patch_size=16,\n",
    "            num_transformer_layers=1,\n",
    "            embedding_dim=384,\n",
    "            mlp_size=1024,\n",
    "            num_heads=12,\n",
    "            attn_dropout=0,\n",
    "            mlp_dropout=0.1,\n",
    "            embedding_dropout=0.1,\n",
    "            num_classes=len(training_data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560074"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct, test_loss\n",
    "\n",
    "def train(dataloader,model,loss_fn,optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for batch, (X,y) in  enumerate (dataloader):\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        #back propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 100 == 0:\n",
    "            avg_loss += loss.item()\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return avg_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.404041  [   16/10000]\n",
      "loss: 2.429628  [  176/10000]\n",
      "loss: 2.424626  [  336/10000]\n",
      "loss: 2.199780  [  496/10000]\n",
      "loss: 2.302136  [  656/10000]\n",
      "loss: 2.120612  [  816/10000]\n",
      "loss: 2.226849  [  976/10000]\n",
      "loss: 2.191674  [ 1136/10000]\n",
      "loss: 1.842687  [ 1296/10000]\n",
      "loss: 1.873313  [ 1456/10000]\n",
      "loss: 1.905916  [ 1616/10000]\n",
      "loss: 1.553781  [ 1776/10000]\n",
      "loss: 1.662016  [ 1936/10000]\n",
      "loss: 1.164260  [ 2096/10000]\n",
      "loss: 1.142552  [ 2256/10000]\n",
      "loss: 1.208619  [ 2416/10000]\n",
      "loss: 1.094178  [ 2576/10000]\n",
      "loss: 1.331684  [ 2736/10000]\n",
      "loss: 1.173684  [ 2896/10000]\n",
      "loss: 1.398838  [ 3056/10000]\n",
      "loss: 0.976620  [ 3216/10000]\n",
      "loss: 0.876001  [ 3376/10000]\n",
      "loss: 1.063350  [ 3536/10000]\n",
      "loss: 1.174658  [ 3696/10000]\n",
      "loss: 0.856165  [ 3856/10000]\n",
      "loss: 1.534769  [ 4016/10000]\n",
      "loss: 1.151906  [ 4176/10000]\n",
      "loss: 0.729802  [ 4336/10000]\n",
      "loss: 1.082898  [ 4496/10000]\n",
      "loss: 0.870005  [ 4656/10000]\n",
      "loss: 0.771620  [ 4816/10000]\n",
      "loss: 1.047502  [ 4976/10000]\n",
      "loss: 0.840930  [ 5136/10000]\n",
      "loss: 0.790522  [ 5296/10000]\n",
      "loss: 0.824355  [ 5456/10000]\n",
      "loss: 1.061523  [ 5616/10000]\n",
      "loss: 0.920806  [ 5776/10000]\n",
      "loss: 1.403375  [ 5936/10000]\n",
      "loss: 1.101191  [ 6096/10000]\n",
      "loss: 0.753729  [ 6256/10000]\n",
      "loss: 1.064650  [ 6416/10000]\n",
      "loss: 0.721962  [ 6576/10000]\n",
      "loss: 1.019079  [ 6736/10000]\n",
      "loss: 0.821884  [ 6896/10000]\n",
      "loss: 0.980240  [ 7056/10000]\n",
      "loss: 0.975475  [ 7216/10000]\n",
      "loss: 0.893620  [ 7376/10000]\n",
      "loss: 1.045623  [ 7536/10000]\n",
      "loss: 0.466986  [ 7696/10000]\n",
      "loss: 1.288711  [ 7856/10000]\n",
      "loss: 0.508769  [ 8016/10000]\n",
      "loss: 0.653078  [ 8176/10000]\n",
      "loss: 0.903720  [ 8336/10000]\n",
      "loss: 0.567826  [ 8496/10000]\n",
      "loss: 1.008915  [ 8656/10000]\n",
      "loss: 0.573552  [ 8816/10000]\n",
      "loss: 1.010903  [ 8976/10000]\n",
      "loss: 0.867346  [ 9136/10000]\n",
      "loss: 0.713949  [ 9296/10000]\n",
      "loss: 0.530267  [ 9456/10000]\n",
      "loss: 0.703013  [ 9616/10000]\n",
      "loss: 0.955737  [ 9776/10000]\n",
      "loss: 0.860443  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.757446 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.880769  [   16/10000]\n",
      "loss: 0.471010  [  176/10000]\n",
      "loss: 1.018278  [  336/10000]\n",
      "loss: 0.690088  [  496/10000]\n",
      "loss: 0.839286  [  656/10000]\n",
      "loss: 0.958846  [  816/10000]\n",
      "loss: 0.809710  [  976/10000]\n",
      "loss: 0.942780  [ 1136/10000]\n",
      "loss: 0.709689  [ 1296/10000]\n",
      "loss: 0.572000  [ 1456/10000]\n",
      "loss: 0.734684  [ 1616/10000]\n",
      "loss: 0.691590  [ 1776/10000]\n",
      "loss: 0.785982  [ 1936/10000]\n",
      "loss: 0.669834  [ 2096/10000]\n",
      "loss: 0.449516  [ 2256/10000]\n",
      "loss: 0.607249  [ 2416/10000]\n",
      "loss: 0.813432  [ 2576/10000]\n",
      "loss: 0.818028  [ 2736/10000]\n",
      "loss: 0.808004  [ 2896/10000]\n",
      "loss: 0.964289  [ 3056/10000]\n",
      "loss: 0.612136  [ 3216/10000]\n",
      "loss: 0.581926  [ 3376/10000]\n",
      "loss: 1.001401  [ 3536/10000]\n",
      "loss: 1.048370  [ 3696/10000]\n",
      "loss: 0.285712  [ 3856/10000]\n",
      "loss: 1.031446  [ 4016/10000]\n",
      "loss: 0.939515  [ 4176/10000]\n",
      "loss: 0.639805  [ 4336/10000]\n",
      "loss: 0.712835  [ 4496/10000]\n",
      "loss: 0.797241  [ 4656/10000]\n",
      "loss: 0.604064  [ 4816/10000]\n",
      "loss: 0.691878  [ 4976/10000]\n",
      "loss: 0.676455  [ 5136/10000]\n",
      "loss: 0.655780  [ 5296/10000]\n",
      "loss: 0.671585  [ 5456/10000]\n",
      "loss: 0.602470  [ 5616/10000]\n",
      "loss: 0.573817  [ 5776/10000]\n",
      "loss: 1.160416  [ 5936/10000]\n",
      "loss: 0.996911  [ 6096/10000]\n",
      "loss: 0.550575  [ 6256/10000]\n",
      "loss: 1.049870  [ 6416/10000]\n",
      "loss: 0.551274  [ 6576/10000]\n",
      "loss: 0.753099  [ 6736/10000]\n",
      "loss: 0.634177  [ 6896/10000]\n",
      "loss: 0.852664  [ 7056/10000]\n",
      "loss: 0.725581  [ 7216/10000]\n",
      "loss: 0.701237  [ 7376/10000]\n",
      "loss: 0.647880  [ 7536/10000]\n",
      "loss: 0.498086  [ 7696/10000]\n",
      "loss: 0.794304  [ 7856/10000]\n",
      "loss: 0.521167  [ 8016/10000]\n",
      "loss: 0.579473  [ 8176/10000]\n",
      "loss: 0.710431  [ 8336/10000]\n",
      "loss: 0.603332  [ 8496/10000]\n",
      "loss: 0.935877  [ 8656/10000]\n",
      "loss: 0.252012  [ 8816/10000]\n",
      "loss: 0.926954  [ 8976/10000]\n",
      "loss: 0.707816  [ 9136/10000]\n",
      "loss: 0.500772  [ 9296/10000]\n",
      "loss: 0.493201  [ 9456/10000]\n",
      "loss: 0.646638  [ 9616/10000]\n",
      "loss: 0.677622  [ 9776/10000]\n",
      "loss: 0.737086  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.682218 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.855701  [   16/10000]\n",
      "loss: 0.462646  [  176/10000]\n",
      "loss: 1.012507  [  336/10000]\n",
      "loss: 0.504668  [  496/10000]\n",
      "loss: 0.644543  [  656/10000]\n",
      "loss: 0.872420  [  816/10000]\n",
      "loss: 0.606722  [  976/10000]\n",
      "loss: 0.795355  [ 1136/10000]\n",
      "loss: 0.631645  [ 1296/10000]\n",
      "loss: 0.606804  [ 1456/10000]\n",
      "loss: 0.755648  [ 1616/10000]\n",
      "loss: 0.559312  [ 1776/10000]\n",
      "loss: 0.576507  [ 1936/10000]\n",
      "loss: 0.821893  [ 2096/10000]\n",
      "loss: 0.346692  [ 2256/10000]\n",
      "loss: 0.497786  [ 2416/10000]\n",
      "loss: 0.775560  [ 2576/10000]\n",
      "loss: 0.821176  [ 2736/10000]\n",
      "loss: 0.605114  [ 2896/10000]\n",
      "loss: 0.874549  [ 3056/10000]\n",
      "loss: 0.447807  [ 3216/10000]\n",
      "loss: 0.456341  [ 3376/10000]\n",
      "loss: 1.054513  [ 3536/10000]\n",
      "loss: 1.024026  [ 3696/10000]\n",
      "loss: 0.251702  [ 3856/10000]\n",
      "loss: 0.831953  [ 4016/10000]\n",
      "loss: 0.894454  [ 4176/10000]\n",
      "loss: 0.461004  [ 4336/10000]\n",
      "loss: 0.613483  [ 4496/10000]\n",
      "loss: 0.919099  [ 4656/10000]\n",
      "loss: 0.670320  [ 4816/10000]\n",
      "loss: 0.521226  [ 4976/10000]\n",
      "loss: 0.593950  [ 5136/10000]\n",
      "loss: 0.458282  [ 5296/10000]\n",
      "loss: 0.520361  [ 5456/10000]\n",
      "loss: 0.502558  [ 5616/10000]\n",
      "loss: 0.696376  [ 5776/10000]\n",
      "loss: 0.993299  [ 5936/10000]\n",
      "loss: 0.993936  [ 6096/10000]\n",
      "loss: 0.596378  [ 6256/10000]\n",
      "loss: 0.922103  [ 6416/10000]\n",
      "loss: 0.516726  [ 6576/10000]\n",
      "loss: 0.753671  [ 6736/10000]\n",
      "loss: 0.565089  [ 6896/10000]\n",
      "loss: 0.804613  [ 7056/10000]\n",
      "loss: 0.538920  [ 7216/10000]\n",
      "loss: 0.744495  [ 7376/10000]\n",
      "loss: 0.632037  [ 7536/10000]\n",
      "loss: 0.406376  [ 7696/10000]\n",
      "loss: 0.675100  [ 7856/10000]\n",
      "loss: 0.398383  [ 8016/10000]\n",
      "loss: 0.360145  [ 8176/10000]\n",
      "loss: 0.499005  [ 8336/10000]\n",
      "loss: 0.652951  [ 8496/10000]\n",
      "loss: 1.043441  [ 8656/10000]\n",
      "loss: 0.362392  [ 8816/10000]\n",
      "loss: 0.930366  [ 8976/10000]\n",
      "loss: 0.781082  [ 9136/10000]\n",
      "loss: 0.442299  [ 9296/10000]\n",
      "loss: 0.346520  [ 9456/10000]\n",
      "loss: 0.596005  [ 9616/10000]\n",
      "loss: 0.566604  [ 9776/10000]\n",
      "loss: 0.797917  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.650521 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.720481  [   16/10000]\n",
      "loss: 0.342752  [  176/10000]\n",
      "loss: 0.985513  [  336/10000]\n",
      "loss: 0.471282  [  496/10000]\n",
      "loss: 0.703307  [  656/10000]\n",
      "loss: 0.825294  [  816/10000]\n",
      "loss: 0.511652  [  976/10000]\n",
      "loss: 0.578377  [ 1136/10000]\n",
      "loss: 0.578697  [ 1296/10000]\n",
      "loss: 0.657605  [ 1456/10000]\n",
      "loss: 0.638475  [ 1616/10000]\n",
      "loss: 0.604438  [ 1776/10000]\n",
      "loss: 0.515063  [ 1936/10000]\n",
      "loss: 0.739739  [ 2096/10000]\n",
      "loss: 0.314294  [ 2256/10000]\n",
      "loss: 0.376581  [ 2416/10000]\n",
      "loss: 0.805888  [ 2576/10000]\n",
      "loss: 0.807624  [ 2736/10000]\n",
      "loss: 0.517996  [ 2896/10000]\n",
      "loss: 0.817296  [ 3056/10000]\n",
      "loss: 0.524626  [ 3216/10000]\n",
      "loss: 0.506298  [ 3376/10000]\n",
      "loss: 1.025410  [ 3536/10000]\n",
      "loss: 1.017658  [ 3696/10000]\n",
      "loss: 0.211652  [ 3856/10000]\n",
      "loss: 0.787104  [ 4016/10000]\n",
      "loss: 0.921920  [ 4176/10000]\n",
      "loss: 0.375491  [ 4336/10000]\n",
      "loss: 0.640224  [ 4496/10000]\n",
      "loss: 0.986923  [ 4656/10000]\n",
      "loss: 0.674470  [ 4816/10000]\n",
      "loss: 0.345275  [ 4976/10000]\n",
      "loss: 0.597520  [ 5136/10000]\n",
      "loss: 0.372732  [ 5296/10000]\n",
      "loss: 0.564725  [ 5456/10000]\n",
      "loss: 0.606933  [ 5616/10000]\n",
      "loss: 0.627255  [ 5776/10000]\n",
      "loss: 0.875771  [ 5936/10000]\n",
      "loss: 1.035682  [ 6096/10000]\n",
      "loss: 0.604137  [ 6256/10000]\n",
      "loss: 0.975654  [ 6416/10000]\n",
      "loss: 0.544937  [ 6576/10000]\n",
      "loss: 0.553662  [ 6736/10000]\n",
      "loss: 0.541357  [ 6896/10000]\n",
      "loss: 0.636694  [ 7056/10000]\n",
      "loss: 0.416399  [ 7216/10000]\n",
      "loss: 0.718380  [ 7376/10000]\n",
      "loss: 0.609048  [ 7536/10000]\n",
      "loss: 0.356310  [ 7696/10000]\n",
      "loss: 0.803250  [ 7856/10000]\n",
      "loss: 0.389211  [ 8016/10000]\n",
      "loss: 0.401788  [ 8176/10000]\n",
      "loss: 0.496239  [ 8336/10000]\n",
      "loss: 0.653392  [ 8496/10000]\n",
      "loss: 1.008008  [ 8656/10000]\n",
      "loss: 0.229902  [ 8816/10000]\n",
      "loss: 0.855254  [ 8976/10000]\n",
      "loss: 0.619974  [ 9136/10000]\n",
      "loss: 0.417766  [ 9296/10000]\n",
      "loss: 0.313166  [ 9456/10000]\n",
      "loss: 0.493598  [ 9616/10000]\n",
      "loss: 0.592230  [ 9776/10000]\n",
      "loss: 0.763451  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.626474 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.778295  [   16/10000]\n",
      "loss: 0.394677  [  176/10000]\n",
      "loss: 1.011051  [  336/10000]\n",
      "loss: 0.537027  [  496/10000]\n",
      "loss: 0.661616  [  656/10000]\n",
      "loss: 0.723278  [  816/10000]\n",
      "loss: 0.596983  [  976/10000]\n",
      "loss: 0.443040  [ 1136/10000]\n",
      "loss: 0.555379  [ 1296/10000]\n",
      "loss: 0.628836  [ 1456/10000]\n",
      "loss: 0.862697  [ 1616/10000]\n",
      "loss: 0.594033  [ 1776/10000]\n",
      "loss: 0.465633  [ 1936/10000]\n",
      "loss: 0.588346  [ 2096/10000]\n",
      "loss: 0.315109  [ 2256/10000]\n",
      "loss: 0.321628  [ 2416/10000]\n",
      "loss: 0.787459  [ 2576/10000]\n",
      "loss: 0.882127  [ 2736/10000]\n",
      "loss: 0.569856  [ 2896/10000]\n",
      "loss: 0.794392  [ 3056/10000]\n",
      "loss: 0.490961  [ 3216/10000]\n",
      "loss: 0.423541  [ 3376/10000]\n",
      "loss: 1.056129  [ 3536/10000]\n",
      "loss: 0.974441  [ 3696/10000]\n",
      "loss: 0.243102  [ 3856/10000]\n",
      "loss: 0.807016  [ 4016/10000]\n",
      "loss: 0.794325  [ 4176/10000]\n",
      "loss: 0.351689  [ 4336/10000]\n",
      "loss: 0.595757  [ 4496/10000]\n",
      "loss: 1.045900  [ 4656/10000]\n",
      "loss: 0.617601  [ 4816/10000]\n",
      "loss: 0.385154  [ 4976/10000]\n",
      "loss: 0.492143  [ 5136/10000]\n",
      "loss: 0.232347  [ 5296/10000]\n",
      "loss: 0.518293  [ 5456/10000]\n",
      "loss: 0.377841  [ 5616/10000]\n",
      "loss: 0.463296  [ 5776/10000]\n",
      "loss: 0.769508  [ 5936/10000]\n",
      "loss: 1.058811  [ 6096/10000]\n",
      "loss: 0.456712  [ 6256/10000]\n",
      "loss: 0.855970  [ 6416/10000]\n",
      "loss: 0.334687  [ 6576/10000]\n",
      "loss: 0.683690  [ 6736/10000]\n",
      "loss: 0.688577  [ 6896/10000]\n",
      "loss: 0.610643  [ 7056/10000]\n",
      "loss: 0.400732  [ 7216/10000]\n",
      "loss: 0.715893  [ 7376/10000]\n",
      "loss: 0.655174  [ 7536/10000]\n",
      "loss: 0.265996  [ 7696/10000]\n",
      "loss: 0.885233  [ 7856/10000]\n",
      "loss: 0.428986  [ 8016/10000]\n",
      "loss: 0.346859  [ 8176/10000]\n",
      "loss: 0.523115  [ 8336/10000]\n",
      "loss: 0.605385  [ 8496/10000]\n",
      "loss: 0.887069  [ 8656/10000]\n",
      "loss: 0.214973  [ 8816/10000]\n",
      "loss: 0.856631  [ 8976/10000]\n",
      "loss: 0.475144  [ 9136/10000]\n",
      "loss: 0.369645  [ 9296/10000]\n",
      "loss: 0.306169  [ 9456/10000]\n",
      "loss: 0.515191  [ 9616/10000]\n",
      "loss: 0.601008  [ 9776/10000]\n",
      "loss: 0.705705  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.612381 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.675539  [   16/10000]\n",
      "loss: 0.339267  [  176/10000]\n",
      "loss: 0.831738  [  336/10000]\n",
      "loss: 0.580566  [  496/10000]\n",
      "loss: 0.735551  [  656/10000]\n",
      "loss: 0.716576  [  816/10000]\n",
      "loss: 0.457551  [  976/10000]\n",
      "loss: 0.463683  [ 1136/10000]\n",
      "loss: 0.591098  [ 1296/10000]\n",
      "loss: 0.690478  [ 1456/10000]\n",
      "loss: 0.781794  [ 1616/10000]\n",
      "loss: 0.457507  [ 1776/10000]\n",
      "loss: 0.457526  [ 1936/10000]\n",
      "loss: 0.529827  [ 2096/10000]\n",
      "loss: 0.319535  [ 2256/10000]\n",
      "loss: 0.268612  [ 2416/10000]\n",
      "loss: 0.833940  [ 2576/10000]\n",
      "loss: 0.855633  [ 2736/10000]\n",
      "loss: 0.552375  [ 2896/10000]\n",
      "loss: 0.747370  [ 3056/10000]\n",
      "loss: 0.391884  [ 3216/10000]\n",
      "loss: 0.326348  [ 3376/10000]\n",
      "loss: 1.156553  [ 3536/10000]\n",
      "loss: 0.836660  [ 3696/10000]\n",
      "loss: 0.178355  [ 3856/10000]\n",
      "loss: 0.882700  [ 4016/10000]\n",
      "loss: 0.695507  [ 4176/10000]\n",
      "loss: 0.331025  [ 4336/10000]\n",
      "loss: 0.565595  [ 4496/10000]\n",
      "loss: 0.902448  [ 4656/10000]\n",
      "loss: 0.618902  [ 4816/10000]\n",
      "loss: 0.333296  [ 4976/10000]\n",
      "loss: 0.416222  [ 5136/10000]\n",
      "loss: 0.251504  [ 5296/10000]\n",
      "loss: 0.585698  [ 5456/10000]\n",
      "loss: 0.344932  [ 5616/10000]\n",
      "loss: 0.564105  [ 5776/10000]\n",
      "loss: 0.851772  [ 5936/10000]\n",
      "loss: 1.009786  [ 6096/10000]\n",
      "loss: 0.425779  [ 6256/10000]\n",
      "loss: 0.736116  [ 6416/10000]\n",
      "loss: 0.307747  [ 6576/10000]\n",
      "loss: 0.602553  [ 6736/10000]\n",
      "loss: 0.544965  [ 6896/10000]\n",
      "loss: 0.535911  [ 7056/10000]\n",
      "loss: 0.383934  [ 7216/10000]\n",
      "loss: 0.715416  [ 7376/10000]\n",
      "loss: 0.482870  [ 7536/10000]\n",
      "loss: 0.356742  [ 7696/10000]\n",
      "loss: 0.933588  [ 7856/10000]\n",
      "loss: 0.312199  [ 8016/10000]\n",
      "loss: 0.337075  [ 8176/10000]\n",
      "loss: 0.458708  [ 8336/10000]\n",
      "loss: 0.608317  [ 8496/10000]\n",
      "loss: 0.810209  [ 8656/10000]\n",
      "loss: 0.236541  [ 8816/10000]\n",
      "loss: 0.894485  [ 8976/10000]\n",
      "loss: 0.459204  [ 9136/10000]\n",
      "loss: 0.365698  [ 9296/10000]\n",
      "loss: 0.217646  [ 9456/10000]\n",
      "loss: 0.426161  [ 9616/10000]\n",
      "loss: 0.495865  [ 9776/10000]\n",
      "loss: 0.834491  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.614560 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.669562  [   16/10000]\n",
      "loss: 0.372932  [  176/10000]\n",
      "loss: 0.752535  [  336/10000]\n",
      "loss: 0.525916  [  496/10000]\n",
      "loss: 0.808413  [  656/10000]\n",
      "loss: 0.990679  [  816/10000]\n",
      "loss: 0.572189  [  976/10000]\n",
      "loss: 0.395706  [ 1136/10000]\n",
      "loss: 0.678321  [ 1296/10000]\n",
      "loss: 0.522711  [ 1456/10000]\n",
      "loss: 0.931219  [ 1616/10000]\n",
      "loss: 0.489183  [ 1776/10000]\n",
      "loss: 0.421124  [ 1936/10000]\n",
      "loss: 0.623769  [ 2096/10000]\n",
      "loss: 0.305578  [ 2256/10000]\n",
      "loss: 0.279552  [ 2416/10000]\n",
      "loss: 0.700529  [ 2576/10000]\n",
      "loss: 0.532514  [ 2736/10000]\n",
      "loss: 0.635730  [ 2896/10000]\n",
      "loss: 0.705185  [ 3056/10000]\n",
      "loss: 0.416356  [ 3216/10000]\n",
      "loss: 0.373510  [ 3376/10000]\n",
      "loss: 1.004432  [ 3536/10000]\n",
      "loss: 0.826165  [ 3696/10000]\n",
      "loss: 0.165377  [ 3856/10000]\n",
      "loss: 0.807458  [ 4016/10000]\n",
      "loss: 0.804497  [ 4176/10000]\n",
      "loss: 0.300593  [ 4336/10000]\n",
      "loss: 0.660002  [ 4496/10000]\n",
      "loss: 0.914122  [ 4656/10000]\n",
      "loss: 0.671173  [ 4816/10000]\n",
      "loss: 0.319936  [ 4976/10000]\n",
      "loss: 0.412363  [ 5136/10000]\n",
      "loss: 0.193890  [ 5296/10000]\n",
      "loss: 0.581381  [ 5456/10000]\n",
      "loss: 0.449245  [ 5616/10000]\n",
      "loss: 0.710897  [ 5776/10000]\n",
      "loss: 0.684297  [ 5936/10000]\n",
      "loss: 0.944833  [ 6096/10000]\n",
      "loss: 0.390391  [ 6256/10000]\n",
      "loss: 0.579947  [ 6416/10000]\n",
      "loss: 0.214585  [ 6576/10000]\n",
      "loss: 0.522502  [ 6736/10000]\n",
      "loss: 0.608603  [ 6896/10000]\n",
      "loss: 0.508931  [ 7056/10000]\n",
      "loss: 0.435818  [ 7216/10000]\n",
      "loss: 0.600499  [ 7376/10000]\n",
      "loss: 0.386358  [ 7536/10000]\n",
      "loss: 0.234052  [ 7696/10000]\n",
      "loss: 0.889300  [ 7856/10000]\n",
      "loss: 0.357657  [ 8016/10000]\n",
      "loss: 0.297299  [ 8176/10000]\n",
      "loss: 0.516917  [ 8336/10000]\n",
      "loss: 0.656184  [ 8496/10000]\n",
      "loss: 0.844404  [ 8656/10000]\n",
      "loss: 0.195636  [ 8816/10000]\n",
      "loss: 0.797721  [ 8976/10000]\n",
      "loss: 0.449690  [ 9136/10000]\n",
      "loss: 0.296803  [ 9296/10000]\n",
      "loss: 0.183448  [ 9456/10000]\n",
      "loss: 0.500485  [ 9616/10000]\n",
      "loss: 0.422819  [ 9776/10000]\n",
      "loss: 0.692076  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.583286 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.563560  [   16/10000]\n",
      "loss: 0.306949  [  176/10000]\n",
      "loss: 0.881684  [  336/10000]\n",
      "loss: 0.412531  [  496/10000]\n",
      "loss: 0.704338  [  656/10000]\n",
      "loss: 0.859102  [  816/10000]\n",
      "loss: 0.565865  [  976/10000]\n",
      "loss: 0.315741  [ 1136/10000]\n",
      "loss: 0.700459  [ 1296/10000]\n",
      "loss: 0.623881  [ 1456/10000]\n",
      "loss: 1.037979  [ 1616/10000]\n",
      "loss: 0.433993  [ 1776/10000]\n",
      "loss: 0.578313  [ 1936/10000]\n",
      "loss: 0.464735  [ 2096/10000]\n",
      "loss: 0.270342  [ 2256/10000]\n",
      "loss: 0.215430  [ 2416/10000]\n",
      "loss: 0.910218  [ 2576/10000]\n",
      "loss: 0.636952  [ 2736/10000]\n",
      "loss: 0.603360  [ 2896/10000]\n",
      "loss: 0.656989  [ 3056/10000]\n",
      "loss: 0.430164  [ 3216/10000]\n",
      "loss: 0.399902  [ 3376/10000]\n",
      "loss: 0.865270  [ 3536/10000]\n",
      "loss: 0.838408  [ 3696/10000]\n",
      "loss: 0.163940  [ 3856/10000]\n",
      "loss: 0.757965  [ 4016/10000]\n",
      "loss: 0.711645  [ 4176/10000]\n",
      "loss: 0.263429  [ 4336/10000]\n",
      "loss: 0.725090  [ 4496/10000]\n",
      "loss: 0.734043  [ 4656/10000]\n",
      "loss: 0.604049  [ 4816/10000]\n",
      "loss: 0.315132  [ 4976/10000]\n",
      "loss: 0.320850  [ 5136/10000]\n",
      "loss: 0.195302  [ 5296/10000]\n",
      "loss: 0.501437  [ 5456/10000]\n",
      "loss: 0.402148  [ 5616/10000]\n",
      "loss: 0.672620  [ 5776/10000]\n",
      "loss: 0.696465  [ 5936/10000]\n",
      "loss: 0.933227  [ 6096/10000]\n",
      "loss: 0.427190  [ 6256/10000]\n",
      "loss: 0.549420  [ 6416/10000]\n",
      "loss: 0.328816  [ 6576/10000]\n",
      "loss: 0.474873  [ 6736/10000]\n",
      "loss: 0.634558  [ 6896/10000]\n",
      "loss: 0.465282  [ 7056/10000]\n",
      "loss: 0.421560  [ 7216/10000]\n",
      "loss: 0.635046  [ 7376/10000]\n",
      "loss: 0.396422  [ 7536/10000]\n",
      "loss: 0.171828  [ 7696/10000]\n",
      "loss: 0.882768  [ 7856/10000]\n",
      "loss: 0.254399  [ 8016/10000]\n",
      "loss: 0.344127  [ 8176/10000]\n",
      "loss: 0.459807  [ 8336/10000]\n",
      "loss: 0.610161  [ 8496/10000]\n",
      "loss: 0.704192  [ 8656/10000]\n",
      "loss: 0.228417  [ 8816/10000]\n",
      "loss: 0.782152  [ 8976/10000]\n",
      "loss: 0.343434  [ 9136/10000]\n",
      "loss: 0.307155  [ 9296/10000]\n",
      "loss: 0.228261  [ 9456/10000]\n",
      "loss: 0.471292  [ 9616/10000]\n",
      "loss: 0.497454  [ 9776/10000]\n",
      "loss: 0.810487  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.569374 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.649766  [   16/10000]\n",
      "loss: 0.261547  [  176/10000]\n",
      "loss: 0.859412  [  336/10000]\n",
      "loss: 0.410819  [  496/10000]\n",
      "loss: 0.744266  [  656/10000]\n",
      "loss: 0.816762  [  816/10000]\n",
      "loss: 0.506960  [  976/10000]\n",
      "loss: 0.275907  [ 1136/10000]\n",
      "loss: 0.620047  [ 1296/10000]\n",
      "loss: 0.447417  [ 1456/10000]\n",
      "loss: 0.687423  [ 1616/10000]\n",
      "loss: 0.491542  [ 1776/10000]\n",
      "loss: 0.477405  [ 1936/10000]\n",
      "loss: 0.565963  [ 2096/10000]\n",
      "loss: 0.255682  [ 2256/10000]\n",
      "loss: 0.308764  [ 2416/10000]\n",
      "loss: 1.005520  [ 2576/10000]\n",
      "loss: 0.660827  [ 2736/10000]\n",
      "loss: 0.662021  [ 2896/10000]\n",
      "loss: 0.724892  [ 3056/10000]\n",
      "loss: 0.482185  [ 3216/10000]\n",
      "loss: 0.329222  [ 3376/10000]\n",
      "loss: 1.000268  [ 3536/10000]\n",
      "loss: 0.790878  [ 3696/10000]\n",
      "loss: 0.173184  [ 3856/10000]\n",
      "loss: 0.638062  [ 4016/10000]\n",
      "loss: 0.683021  [ 4176/10000]\n",
      "loss: 0.289685  [ 4336/10000]\n",
      "loss: 0.750991  [ 4496/10000]\n",
      "loss: 0.760286  [ 4656/10000]\n",
      "loss: 0.474774  [ 4816/10000]\n",
      "loss: 0.269354  [ 4976/10000]\n",
      "loss: 0.400232  [ 5136/10000]\n",
      "loss: 0.209343  [ 5296/10000]\n",
      "loss: 0.533821  [ 5456/10000]\n",
      "loss: 0.424956  [ 5616/10000]\n",
      "loss: 0.640685  [ 5776/10000]\n",
      "loss: 0.640352  [ 5936/10000]\n",
      "loss: 0.881104  [ 6096/10000]\n",
      "loss: 0.344187  [ 6256/10000]\n",
      "loss: 0.601223  [ 6416/10000]\n",
      "loss: 0.292063  [ 6576/10000]\n",
      "loss: 0.499226  [ 6736/10000]\n",
      "loss: 0.583625  [ 6896/10000]\n",
      "loss: 0.485357  [ 7056/10000]\n",
      "loss: 0.485015  [ 7216/10000]\n",
      "loss: 0.612025  [ 7376/10000]\n",
      "loss: 0.465171  [ 7536/10000]\n",
      "loss: 0.216596  [ 7696/10000]\n",
      "loss: 0.969762  [ 7856/10000]\n",
      "loss: 0.264156  [ 8016/10000]\n",
      "loss: 0.296748  [ 8176/10000]\n",
      "loss: 0.397149  [ 8336/10000]\n",
      "loss: 0.548863  [ 8496/10000]\n",
      "loss: 0.807253  [ 8656/10000]\n",
      "loss: 0.181612  [ 8816/10000]\n",
      "loss: 0.777400  [ 8976/10000]\n",
      "loss: 0.354036  [ 9136/10000]\n",
      "loss: 0.315249  [ 9296/10000]\n",
      "loss: 0.207379  [ 9456/10000]\n",
      "loss: 0.609683  [ 9616/10000]\n",
      "loss: 0.382269  [ 9776/10000]\n",
      "loss: 0.719293  [ 9936/10000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.588085 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.530455  [   16/10000]\n",
      "loss: 0.383972  [  176/10000]\n",
      "loss: 0.765755  [  336/10000]\n",
      "loss: 0.471699  [  496/10000]\n",
      "loss: 0.586626  [  656/10000]\n",
      "loss: 0.886982  [  816/10000]\n",
      "loss: 0.496480  [  976/10000]\n",
      "loss: 0.260896  [ 1136/10000]\n",
      "loss: 0.565068  [ 1296/10000]\n",
      "loss: 0.355698  [ 1456/10000]\n",
      "loss: 0.849772  [ 1616/10000]\n",
      "loss: 0.379228  [ 1776/10000]\n",
      "loss: 0.526294  [ 1936/10000]\n",
      "loss: 0.568340  [ 2096/10000]\n",
      "loss: 0.251823  [ 2256/10000]\n",
      "loss: 0.235791  [ 2416/10000]\n",
      "loss: 0.800668  [ 2576/10000]\n",
      "loss: 0.510151  [ 2736/10000]\n",
      "loss: 0.630666  [ 2896/10000]\n",
      "loss: 0.710833  [ 3056/10000]\n",
      "loss: 0.462785  [ 3216/10000]\n",
      "loss: 0.291595  [ 3376/10000]\n",
      "loss: 0.901754  [ 3536/10000]\n",
      "loss: 1.024148  [ 3696/10000]\n",
      "loss: 0.168012  [ 3856/10000]\n",
      "loss: 0.879184  [ 4016/10000]\n",
      "loss: 0.763657  [ 4176/10000]\n",
      "loss: 0.255295  [ 4336/10000]\n",
      "loss: 0.714631  [ 4496/10000]\n",
      "loss: 0.776943  [ 4656/10000]\n",
      "loss: 0.429745  [ 4816/10000]\n",
      "loss: 0.325484  [ 4976/10000]\n",
      "loss: 0.268412  [ 5136/10000]\n",
      "loss: 0.212721  [ 5296/10000]\n",
      "loss: 0.464942  [ 5456/10000]\n",
      "loss: 0.372445  [ 5616/10000]\n",
      "loss: 0.579804  [ 5776/10000]\n",
      "loss: 0.574476  [ 5936/10000]\n",
      "loss: 1.014599  [ 6096/10000]\n",
      "loss: 0.330572  [ 6256/10000]\n",
      "loss: 0.530100  [ 6416/10000]\n",
      "loss: 0.293085  [ 6576/10000]\n",
      "loss: 0.433346  [ 6736/10000]\n",
      "loss: 0.727591  [ 6896/10000]\n",
      "loss: 0.446443  [ 7056/10000]\n",
      "loss: 0.369965  [ 7216/10000]\n",
      "loss: 0.628136  [ 7376/10000]\n",
      "loss: 0.394232  [ 7536/10000]\n",
      "loss: 0.218323  [ 7696/10000]\n",
      "loss: 0.829046  [ 7856/10000]\n",
      "loss: 0.288779  [ 8016/10000]\n",
      "loss: 0.364042  [ 8176/10000]\n",
      "loss: 0.437747  [ 8336/10000]\n",
      "loss: 0.549277  [ 8496/10000]\n",
      "loss: 0.703898  [ 8656/10000]\n",
      "loss: 0.196683  [ 8816/10000]\n",
      "loss: 0.564055  [ 8976/10000]\n",
      "loss: 0.427503  [ 9136/10000]\n",
      "loss: 0.277163  [ 9296/10000]\n",
      "loss: 0.211612  [ 9456/10000]\n",
      "loss: 0.432416  [ 9616/10000]\n",
      "loss: 0.502828  [ 9776/10000]\n",
      "loss: 0.718742  [ 9936/10000]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=1e-4)\n",
    "epochs = 500\n",
    "model.to(device)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
